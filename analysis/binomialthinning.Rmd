---
title: "binomial thinning"
author: "DongyueXie"
date: "2020-03-04"
output:
  workflowr::wflow_html:
    code_folding: hide
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE,message = FALSE)
```

## Introduction

Investigate why effects with larger se are bigger. 

Assume we have $n$ samples and a fraction $p$ of them belong to group 1 and the rest belong to group 2. So $x = (1,1,1,...,1,0,0,0,...,0)^T\in R^n$ and $\sum_ix_i=np$. Under this setting, in simple linear regression $y = a+\beta x + \epsilon$, $\epsilon\sim N(0,\sigma^2)$,  the variance of $\hat\beta$ is $\hat s^2 = \frac{n\sigma^2}{n\sum_ix_i^2-(\sum_ix_i)^2}=\frac{\sigma^2}{np-np^2}$. For fixed $n$ and $p$, if $\hat s$ is large, then this means $\hat\sigma^2$ is large hence $\sigma^2$ is large. 

We now need to figure out the relationship between $\beta$ and $\sigma^2$.

Let's assume we have RNA-Seq count data $z_i\sim Poisson(\lambda)$ for $i=1,2,...,n$. In binomial thinning, $\beta$ is the log2 fold change between groups. Now assume $\beta>0$, according to  Gerard and Stephens(2017), the new(thinned) data vector is $w_i\sim Poisson(\mu_i)$, where $\mu_i=2^{-\beta(1-x_i)}\lambda$. The response $y$ in the simple linear regression is the log transformation of $w$, $y_i=\log(w_i)$, $i=1,2,...n$. 

The Taylor series expansion of $\log w_i$ around $\mu_i$ is $\log(w_i)\approx \log(\mu_i)+\frac{w_i-\mu_i}{\mu_i}$. So the mean of $\log(w_i)$ is $\log(\mu_i) = \lambda - \beta(1-x_i)$ and variance $\frac{1}{\mu_i} = \frac{1}{2^{-\beta(1-x_i)}\lambda}$. So if $\beta$ is large, then $Var(\log(w_i))$ is large if $x_i=0$. This explains the why effects with larger se are bigger.


## Check

For non-null genes $j\in Non.null.gene.set$, choose $p_{1j}+p_{2j}=1$ and $\frac{p_{1j}}{p_{2j}}=\exp(\beta_j)$, and thin the counts $w_{ij}\sim Binomial(z_{ij},p_{\{group.of.i\}j})$, where $z_{ij}$ is the observed counts for $i$th sample, and group of $i$ is either 1 or 2. 

For null genes $j\in Null.gene.set$, $w_{ij}\sim Binomial(z_{ij},0.5)$

```{r}
#'@param Z count matrix, sample by features
#'@param x 1 for group 1, 0 for group 2
#'@param beta effect of fearures,  0 for null.
#'@return W, thinned matrix
bi_thin = function(Z,x,beta){

  n=nrow(Z)
  p=ncol(Z)
  
  # group index
  g1 = which(x==1)
  g2 = which(x==0)
  
  
  p2 = 1/(1+exp(beta))
  p1 = 1-p2
  P = matrix(nrow = n,ncol = p)
  P[g1,] = t(replicate(length(g1),p1))
  P[g2,] = t(replicate(length(g2),p2))
  
  W = matrix(rbinom(n*p,Z,P),nrow=n)
  
  W
}

quiet <- function(x) { 
  sink(tempfile()) 
  on.exit(sink()) 
  invisible(force(x)) 
} 

```

**Normal signal, sd=1.5. Run 50 reps.**

```{r}
library(sva)
load('data/scde/scCDT.RData')
Z = t(as.matrix(CDT))
rm.idx = which(colSums(Z!=0)<10)
Z = Z[,-rm.idx]
n = nrow(Z)
p = ncol(Z)

set.seed(12345)

nreps = 50

loglik=c()
roc_result = c()

for(rep in 1:nreps){
  
x = rbinom(n,1,0.5)
beta = rnorm(p,0,1.5)
beta[sample(1:p,p*0.9)]=0

W = bi_thin(Z,x,beta)

Wn = log(W+0.5)

X = model.matrix(~x)

sva_sva = quiet(sva(t(Wn),mod = X, mod0 = X[, -2, drop = FALSE], n.sv = 3))

X.sva = cbind(X, sva_sva$sv)
lmout = limma::lmFit(object = t(Wn), design = X.sva)
eout  = limma::eBayes(lmout)

svaout           <- list()
svaout$betahat   <- lmout$coefficients[, 2]
svaout$sebetahat <- lmout$stdev.unscaled[, 2] * sqrt(eout$s2.post)
svaout$pvalues   <- eout$p.value[, 2]

sva_limma_ash0 = ashr::ash(svaout$betahat,svaout$sebetahat,alpha=0)

sva_limma_ash1 = ashr::ash(svaout$betahat,svaout$sebetahat,alpha=1)

loglik = rbind(loglik,c(sva_limma_ash0$loglik,sva_limma_ash1$loglik))

#knitr::kable(cbind(sva_limma_ash0$loglik,sva_limma_ash1$loglik), 
#             col.names = c('alpha=0','alpha=1'), digits = 2,caption = 'log-lik')


which_null = ifelse(beta==0,1,0)
################
roc_out <- list(
  #pROC::roc(response = which_null, predictor = c(mout$result$lfsr)),
  #pROC::roc(response = which_null, predictor = c(mout1$result$lfsr)),
  pROC::roc(response = which_null, predictor = c(svaout$pvalues)),
  pROC::roc(response = which_null, predictor = c(sva_limma_ash0$result$lfsr)),
  pROC::roc(response = which_null, predictor = c(sva_limma_ash1$result$lfsr)))
#name_vec <- c("MOUTHWASH0","MOUTHWASH1","SVA-limma","SVA-limma-ash0","SVA-limma-ash1")

auc_vec <- sapply(roc_out, FUN = function(x) { x$auc })
roc_result = rbind(roc_result,auc_vec)

#knitr::kable(sort(auc_vec, decreasing = TRUE), col.names = "AUC", digits = 3)

}

name_vec <- c("sva-limma","sva-limma-ash0","sva-limma-ash1")
colnames(roc_result) <- name_vec

colnames(loglik) = c('alpha=0','alpha=1')

boxplot(loglik,ylab = 'loglik')

boxplot(roc_result,ylab='AUC')

```


